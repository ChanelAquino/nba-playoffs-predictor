---
title: "Analysis of NBA Regular Season to Predict Outcome of 2018 Playoffs"
author: "Chanel Aquino, Dario Molina, Evert Rodriguez"
date: "May 7, 2018"
output: html_document
---

```{r global_options, message=FALSE, warning=FALSE, include=FALSE}
knitr::opts_chunk$set(prompt=TRUE, comment="", echo=T)
```

### Introduction / Data
__championsdata.csv__ contains game-by-game team totals for the championship team from every finals game between 1980 and 2017. __runnerupsdata.csv__ contains game-by-game team totals for the runner-up team from every finals game between 1980 and 2017. The 1980 NBA Finals was the first Finals series since the NBA added the three point line. Both these data sets were downloaded from the [NBA Finals Team Stats](https://www.kaggle.com/daverosenman/nba-finals-team-stats) on [Kaggle.com](kaggle.com). __NBATeamData.csv__ contains current regular season averages per game. 
```{r}
reg.ssn = read.csv("/Users/chanel/School/383_cst/projects/2/nba-playoffs-predictor/NBATeamData.csv", na.strings=c('N/A', 'NA'))
champs = read.csv("/Users/chanel/School/383_cst/projects/2/nba-playoffs-predictor/nba-finals-team-stats/championsdata.csv", na.strings=c('N/A', 'NA'))
r.ups = read.csv("/Users/chanel/School/383_cst/projects/2/nba-playoffs-predictor/nba-finals-team-stats/runnerupsdata.csv", na.strings=c('N/A', 'NA'))
```

### Missing Data
90% of the values in the __nba_finals_appearance__ column in the __reg.ssn__ data set are missing. Therefore, that entire column was removed.
```{r}
# show NA percentages per column
# data - a data frame
show.na.pct = function(data) {
  na.vals = apply(data, 2, function(x) mean(is.na(x)))
  data.frame(na.vals)
}

print("percentage of NA values in reg.ssn")
show.na.pct(reg.ssn) * 100
reg.ssn[['nba_finals_appearance']] = NULL # remove nba_finals_appearance column

print("percentage of NA values in champs")
show.na.pct(champs) * 100
champs = na.omit(champs)

print("percentage of NA values in r.ups")
show.na.pct(r.ups) * 100
r.ups = na.omit(r.ups)
```


### Preprocessing / Cleaning
Here, we renamed the column names in the __reg.ssn__ data set to match the column names in the __champs/r.ups__ data set. We also fixed some spelling errors in some columns as well as created a new column __ot__ in the __champs/r.ups__ data set that would indicate whether a game went into overtime or not (true if value in the __minutes played (mp)__ column > 240).
```{r}
names(reg.ssn) = tolower(names(reg.ssn))
names(champs) = tolower(names(champs))
names(r.ups) = tolower(names(r.ups))

# columns not needed
champs[['x']] = NULL
r.ups[['y']] = NULL


# change reg.ssn column names to match champs and r.ups column names
names(reg.ssn)[3] = 'team'
names(reg.ssn)[15] = 'fg' # field goals made
names(reg.ssn)[17] = 'fgp' # field goal percentage
names(reg.ssn)[18] = 'tp' # 3-point field goals made
names(reg.ssn)[19] = 'tpa' # 3-point field goals attempted
names(reg.ssn)[20] = 'tpp' # 3-point percentage
names(reg.ssn)[21] = 'ft' # free throws made
names(reg.ssn)[23] = 'ftp' # free throw percentage
names(reg.ssn)[24] = 'orb' # offensive rebounds
names(reg.ssn)[25] = 'drb' # defensive rebounds
names(reg.ssn)[26] = 'trb' # total rebounds


# fix spelling errors
unique(champs$team)
champs$team[champs$team == '\'Heat\''] = 'Heat'
champs$team[champs$team == 'Warriorrs'] = 'Warriors'
champs$team = factor(champs$team)

# new column 'ot' to indicate whether game went into overtime
# 'ot' = 1 if 'mp' > 240; else 0
champs$ot = FALSE
champs$ot[champs$mp > 240] = TRUE
# --
r.ups$ot = FALSE
r.ups$ot[r.ups$mp > 240] = TRUE
# --
champs[['mp']] = NULL
r.ups[['mp']] = NULL

# keep only last 10 years of data
pattern = '^20(0[789]|1[[:digit:]])'
rows = grep(pattern, reg.ssn$year)
reg.ssn = reg.ssn[rows, ]
# # --
# rows = grep(pattern, champs$year)
# champs = champs[rows,]
# # --
# rows = grep(pattern, r.ups$year)
# r.ups = r.ups[rows,]
```

### Analysis / Visualization
```{r}
# 
# plot(r.ups[r.ups$win == 0, cols]) # correlation between losses + other columns
# 
# cols = c('gp', 'wins', 'losses', 'po_wins', 'po_losses', 'fg', 'tp', 'ft', 'orb', 'drb', 'ast', 'stl', 'tov', 'blk', 'pts')
# plot(reg.ssn[reg.ssn$po_wins >= 1, cols])
```

### Logistic Regression 1
```{r}
cols = c('game', 'win', 'home', 'fg', 'tp', 'ft', 'orb', 'drb', 'ast', 'stl', 'blk', 'tov', 'pf', 'pts', 'ot')
plot(champs[, cols]) # correlation between wins + other columns
tr_rows = sample(1:nrow(champs), .75*nrow(champs))
tr_dat = champs[tr_rows,]
te_dat = champs[-tr_rows,]
lg.fit1 = glm(win ~ fg + tp + ft + orb + drb, data=tr_dat, family=binomial)
summary(lg.fit1)

actual = te_dat$win
predicted1 = predict(lg.fit1, newdata=te_dat, type='response')
```

### Logistic Regression 2
```{r}
lg.fit2 = glm(win ~ ast + stl + blk + tov, data=tr_dat, family=binomial)
summary(lg.fit2)

predicted2 = predict(lg.fit2, newdata=te_dat, type='response')
```

### Model Assessment: Precision, Recall, and ROC Curves
```{r}
thresh = seq(0, 1, length.out=50) # sequence of threshold values
tpr1 = c() # true positive rate
tpr2 = c()
fpr1 = c() # false positive rate
fpr2 = c()
precision1 = c() # precision
precision2 = c()

for(t in thresh) {
  # model 1
  predicted1 = as.numeric(predicted1 > t)
  precision1 = c(precision1, sum(predicted1 & actual)/sum(predicted1))
  tpr1 = c(tpr1, sum(predicted1 & actual)/sum(actual))
  fpr1 = c(fpr1, sum(predicted1 == 1 & actual == 0)/sum(actual == 0))
  
  # model 2
  predicted2 = as.numeric(predicted2 > t)
  precision2 = c(precision2, sum(predicted2 & actual)/sum(predicted2))
  tpr2 = c(tpr2, sum(predicted2 & actual)/sum(actual))
  fpr2 = c(fpr2, sum(predicted2 == 1 & actual == 0)/sum(actual == 0))
}
```

```{r}
# precision by threshold
plot(thresh, precision1, col='red4', type="l", main='precision by threshold', xlab="thresh", ylab="precision", ylim=c(0.68, 0.75))
par(new=T)
plot(thresh, precision2, col='cornflowerblue', type='l', xlab="thresh", ylab="precision")
legend("topleft", fill=c('red4', 'cornflowerblue'), legend=c('model 1', 'model 2'))
grid()
```


### Conclusion